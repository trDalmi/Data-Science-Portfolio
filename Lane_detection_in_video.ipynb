{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOqVL5ENbn5Ot4Y1f3LpEVc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/trDalmi/Data-Science-Portfolio/blob/main/Lane_detection_in_video.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "TG5Lbslvd2zP"
      },
      "outputs": [],
      "source": [
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab.patches import cv2_imshow"
      ],
      "metadata": {
        "id": "TkI-lieWd91v"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "8JK8KosJeDRw"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def canny(img):\n",
        "  gray =cv2.cvtColor(img,cv2.COLOR_RGB2GRAY)\n",
        "  kernel = 5\n",
        "  blur = cv2.GaussianBlur(gray,(kernel,kernel),0)\n",
        "  canny = cv2.Canny(gray,50,150)\n",
        "  return canny"
      ],
      "metadata": {
        "id": "tQNW5CU1eFY4"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def region_of_intererst(image):\n",
        "  height = image.shape[0]\n",
        "  polygons = np.array([[(200,height),(1100,height),(550,250)]])\n",
        "  mask = np.zeros_like(image)           # full filled black sheet of img np.size\n",
        "  cv2.fillPoly(mask,np.array(polygons),225)          # drawing a polygon on the filter with white infill.\n",
        "  masked_image = cv2.bitwise_and(image,mask)    # Concatenating the mask with the original image using and operator\n",
        "  return masked_image"
      ],
      "metadata": {
        "id": "sebusDosenNt"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_points(image,line):\n",
        "  slope,intercept = line\n",
        "  y1 = int(image.shape[0])\n",
        "  y2 = int(y1*3.0/5)\n",
        "  x1 = int((y1-intercept)/slope)\n",
        "  x2 = int((y2-intercept)/slope)\n",
        "  return [[x1,y1,x2,y2]]"
      ],
      "metadata": {
        "id": "H5vH3bIkn4gp"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def average_slope_intercept(image,lines):\n",
        "  left_fit = []\n",
        "  right_fit = []\n",
        "  if lines is None:\n",
        "    return None\n",
        "  for line in lines:\n",
        "    for x1,y1,x2,y2 in line:\n",
        "      fit = np.polyfit((x1,x2),(y1,y2),1)\n",
        "      slope = fit[0]\n",
        "      intercept = fit[1]\n",
        "      if slope < 0:\n",
        "        left_fit.append((slope,intercept))\n",
        "      else:\n",
        "        right_fit.append((slope,intercept))\n",
        "  left_fit_average = np.average(left_fit,axis=0)\n",
        "  right_fit_average = np.average(right_fit,axis=0)\n",
        "  left_line = make_points(image,left_fit_average)\n",
        "  right_line = make_points(image,right_fit_average)\n",
        "  averaged_lines = [left_line,right_line]\n",
        "  return averaged_lines"
      ],
      "metadata": {
        "id": "S1e36a9coAHk"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def display_lines(img,lines):\n",
        "  line_image = np.zeros_like(img)\n",
        "  if lines is not None:\n",
        "    for line in lines:\n",
        "      for x1,y1,x2,y2 in line:\n",
        "        cv2.line(line_image,(x1,y1),(x2,y2),(255,0,0),10)\n",
        "    return line_image"
      ],
      "metadata": {
        "id": "YcC2vb_Ip1C5"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "arki--uwhpze",
        "outputId": "abfbdad4-6a30-4c4b-86c7-891a4185036c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "video_path = \"/content/drive/MyDrive/data for cv/test2.mp4\"\n",
        "video = cv2.VideoCapture(video_path)"
      ],
      "metadata": {
        "id": "4mQlujPCmbhc"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time"
      ],
      "metadata": {
        "id": "ATzaEh9RqsK_"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "while(video.isOpened()):\n",
        "  _, frame = video.read()\n",
        "  canny_image = canny(frame)\n",
        "  cropped_image = region_of_intererst(canny_image)\n",
        "  lines = cv2.HoughLinesP(cropped_image,2,np.pi/180, 100 ,np.array([]),minLineLength=40,maxLineGap=5)\n",
        "  averaged_lines = average_slope_intercept(frame,lines)\n",
        "  line_image = display_lines(frame,averaged_lines)\n",
        "  combo_image = cv2.addWeighted(frame,0.8,line_image,1,1)\n",
        "  cv2_imshow(combo_image)\n",
        "\n",
        "  if cv2.waitKey(1) & 0xFF == ord('q'):  # Break the loop if 'q' is pressed\n",
        "    break\n",
        "\n",
        "video.release()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "collapsed": true,
        "id": "dmdfs40rnH1W",
        "outputId": "66f7d9a0-46cc-4837-f0f6-2e013e8fb971"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "cannot unpack non-iterable numpy.float64 object",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-e6fbca4237b6>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mcropped_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregion_of_intererst\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcanny_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHoughLinesP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcropped_image\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m180\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mminLineLength\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmaxLineGap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m   \u001b[0maveraged_lines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maverage_slope_intercept\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m   \u001b[0mline_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdisplay_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maveraged_lines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mcombo_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddWeighted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mline_image\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-cbd2da6e96c5>\u001b[0m in \u001b[0;36maverage_slope_intercept\u001b[0;34m(image, lines)\u001b[0m\n\u001b[1;32m     15\u001b[0m   \u001b[0mleft_fit_average\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft_fit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m   \u001b[0mright_fit_average\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright_fit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m   \u001b[0mleft_line\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_points\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mleft_fit_average\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m   \u001b[0mright_line\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_points\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mright_fit_average\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m   \u001b[0maveraged_lines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mleft_line\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mright_line\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-65983f3eaaff>\u001b[0m in \u001b[0;36mmake_points\u001b[0;34m(image, line)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmake_points\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mslope\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mintercept\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0my1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0my2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my1\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m3.0\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mintercept\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mslope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable numpy.float64 object"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Gs2mXASftmxo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}